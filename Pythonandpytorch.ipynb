{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "lab01 solution.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "collapsed": true,
        "id": "5fsCX5JKBvKu"
      },
      "source": [
        "In this, we'll get familiar with the Python programming language and the Pytorch machine learning framework. The combination of Python and Pytorch facilitate rapid machine learning development and experimentation, while also being suitable for production-ready systems. \n",
        "\n",
        "you will:\n",
        " - understand Python syntax and control structures\n",
        " - be familiar with Pytorch tensor operations\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iSsEeTrTBvKv"
      },
      "source": [
        "## Jupyter Notebooks\n",
        "Most of the coding in this subject is done in Jupyter Notebooks. Each Notebook is made up of cells containing either Markdown formatted text (like this cell) or Python code (like those below). You can run a cell by pressing `<SHIFT>+<ENTER>` or the \"Run\" button at the top of the window.\n",
        "\n",
        "#### Code cells\n",
        "Code cells are edited like a typical text-editor, and running one will execute the Python code it contains, with any outputs displayed below it.\n",
        "\n",
        "#### Markdown cells\n",
        "Markdown cells contain Markdown formatted text (like this cell). To edit the contents, just double click on it. Running a Markdown cell applies the formatting.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8xA16MBFBvKw"
      },
      "source": [
        "## Python practice\n",
        "As it's assumed that you have some programming experience, so we'll just explain how Python may differ from other languages you've seen.\n",
        "\n",
        "Even if you're a very experienced programmer, you should still take your time with this practice exercise to get used to coding in Python."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "D5YxvanmBvKx"
      },
      "source": [
        "#### Overview of Python syntax"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "NjbnUzP5BvKx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6b2635ab-6025-495b-8226-46c41b771e41"
      },
      "source": [
        "# This is a comment\n",
        "\n",
        "# Python is dynamically typed, so data types are inferred at runtime\n",
        "msg = \"Hello world\"  # string\n",
        "x = 5  # int\n",
        "y = 3.5  # float\n",
        "z = True  # boolean\n",
        "\n",
        "# There is a 'None' keyword, which is similar to null/NULL in other languages\n",
        "a = None\n",
        "\n",
        "# Integer division produces a float value\n",
        "print(5 / 2)  # 2.5\n",
        "# However, there's another operator if we want the result truncated\n",
        "print(5 // 2)  # 2\n",
        "\n",
        "# Any number of variables can be printed at once\n",
        "print(msg, x, y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "2.5\n",
            "2\n",
            "Hello world 5 3.5\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "zwbeVZrXBvK2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c2eb47d2-3d4c-4c96-8656-4e8a2dfb9961"
      },
      "source": [
        "# Code blocks are indicated using indentation instead of curly braces. If\n",
        "# statements don't require parentheses\n",
        "if x == y:\n",
        "    print(\"x has the same value as y\")\n",
        "else:\n",
        "    print(\"x and y have different values\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x and y have different values\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "KSfJ5uqMBvK5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "441c1c4d-9aab-41f6-f97c-1b4ba62d9c7d"
      },
      "source": [
        "# Chained conditionals use \"elif\" instead of \"else if\"\n",
        "if x < 0:\n",
        "    print(\"x is negative\")\n",
        "elif x > 0:\n",
        "    print(\"x is positive\")\n",
        "else:\n",
        "    print(\"x is zero\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x is positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "MCHvu6WSBvK9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0f71925d-a53f-4623-9a46-eb5db39e1cbb"
      },
      "source": [
        "# Boolean operators are the English words \"and\", \"or\", \"not\"\n",
        "if x > 0 or y > 0:\n",
        "    print(\"at least one of x and y are positive\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "at least one of x and y are positive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "mgzMalOyBvLB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6d18e8d7-7c46-4309-a469-4ccfa7bfa0fd"
      },
      "source": [
        "# while loops don't require parentheses either\n",
        "while x > 0:\n",
        "    print(\"x equals\", x)\n",
        "    x -= 1"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "x equals 5\n",
            "x equals 4\n",
            "x equals 3\n",
            "x equals 2\n",
            "x equals 1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "sr6lAvvvBvLF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8980af24-bb3b-499e-b166-e6f563c9df82"
      },
      "source": [
        "# Functions use the keyword \"def\"\n",
        "def add_two_numbers(num_1, num_2):\n",
        "    return num_1 + num_2\n",
        "\n",
        "summed = add_two_numbers(5, 3)\n",
        "print(summed)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "8\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YScjb54CBvLI"
      },
      "source": [
        "#### Exercise 1\n",
        "<font color='red'>In the next cell, write a function called `maximum` that takes two values and returns the larger of the two, using an if statement.</font>\n",
        "\n",
        "_Ensure that you re-run the cell containing your solution any time you make changes._"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hujx3YLnBvLJ"
      },
      "source": [
        "# TODO: Code your solution here\n",
        "\n",
        "# SOLUTION:\n",
        "def maximum(l, r):\n",
        "    if l > r:\n",
        "        return l\n",
        "    return r\n",
        "\n",
        "# Also valid\n",
        "def maximum(l, r):\n",
        "    return l if l > r else r"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CC4OEZF_BvLP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "163016b7-e36f-4db3-d20d-004bc4e19ab2"
      },
      "source": [
        "# Test your solution here\n",
        "print(maximum(5, 3))   # should output 5\n",
        "print(maximum(-5, 3))  # should output 3\n",
        "print(maximum(0, 0))   # should output 0"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "3\n",
            "0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gRJlo00XBvLS"
      },
      "source": [
        "#### Python lists\n",
        "\n",
        "Python has two ordered data structures - `tuple` and `list`.\n",
        "\n",
        "Lists are the most frequently used of the two, as they are quite flexible and provide many functions to manipulate their entries."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "tHUwDIkbBvLT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "786b762a-c9f2-4ef1-dce8-02bbd57c2492"
      },
      "source": [
        "# Create a list and append to it\n",
        "my_list = [1, 2, 3]\n",
        "my_list.append(4)\n",
        "print(my_list)\n",
        "\n",
        "# The length of the list\n",
        "print(len(my_list))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4]\n",
            "4\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M96dhW5gBvLW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "63209155-25d9-493d-9bd8-51d32d176b56"
      },
      "source": [
        "# Concatenate two lists\n",
        "concat_list = [1, 2, 3] + [4, 5]\n",
        "print(concat_list)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1, 2, 3, 4, 5]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1uOS5wZSBvLZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "12bb5eb3-c1af-47ff-b93b-3aca1f8dd247"
      },
      "source": [
        "# Indexing is zero-based\n",
        "print(my_list[0], my_list[1])\n",
        "\n",
        "# Negative indexing counts from the end of the list\n",
        "print(my_list[-1], my_list[-2])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1 2\n",
            "4 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kXib--mBBvLd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5f382aaa-7234-4d75-e76c-40b61b231696"
      },
      "source": [
        "# Lists and tuples can be iterated over with the \"in\" keyword\n",
        "for x in ['a', 'b', 'c']:\n",
        "    print(x)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "a\n",
            "b\n",
            "c\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Inwjq6-BvLg"
      },
      "source": [
        "Tuples are immutable data structures, which means that their values can't be modified. They should be used where practical, as not only are they faster than lists, their immutability makes your code a little safer. For these reasons, you will mostly see tuples used for short sequences, particularly to describe things like the dimensions of an image.\n",
        "\n",
        "Their entries can be accessed in the same ways as lists like negative indexing, iterating, etc, so it's possible to write code which supports lists and tuples interchangeably - as we'll do in the next exercise."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "X5UJeSW8BvLh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "38b54911-1d99-48d3-ecfe-39d289074257"
      },
      "source": [
        "# Create a tuple. The difference in notation is that lists use square brackets\n",
        "# and tuples use round parentheses\n",
        "my_tuple = (1, 2, 3)\n",
        "\n",
        "print(my_tuple)\n",
        "print(my_tuple[0])\n",
        "\n",
        "# Try to modify a value in-place and see what happens\n",
        "# my_tuple[0] = -1\n",
        "print(my_tuple)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(1, 2, 3)\n",
            "1\n",
            "(1, 2, 3)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sTtyt3lYBvLk"
      },
      "source": [
        "#### Exercise 2\n",
        "<font color='red'>In the next cell, write a function called `arr_max` that takes a list (or tuple) and returns the largest element using a `for` loop and the `maximum` function you wrote in exercise 1. If the list is empty, return `None`.</font>\n",
        "\n",
        "_Ensure that you re-run the cell containing your solution any time you make changes._"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h4N4AaWiBvLl"
      },
      "source": [
        "# TODO: Code your solution here\n",
        "\n",
        "# SOLUTION:\n",
        "def arr_max(my_list):\n",
        "    if len(my_list) == 0:\n",
        "        return None\n",
        "\n",
        "    max_val = my_list[0]\n",
        "    for val in my_list:\n",
        "        max_val = maximum(max_val, val)\n",
        "    return max_val\n",
        "\n",
        "# ALT SOLUTION\n",
        "def arr_max(my_list):\n",
        "    max_val = my_list[0] if my_list else None\n",
        "\n",
        "    for val in my_list:\n",
        "        max_val = maximum(val, max_val)\n",
        "    return max_val"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "GereXwJ4BvLo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "5b2bd3e2-0a88-48e1-c3e0-4f77203f7c04"
      },
      "source": [
        "# Test your solution here\n",
        "print(arr_max([-10, -5, 0, 5]))    # should output 5\n",
        "print(arr_max((-10, -5, 0, 5)))    # should output 5 <-  tuple instead of list\n",
        "print(arr_max([4, -1, 23, 6, -1])) # should output 23\n",
        "print(arr_max([1, 1]))             # should output 1\n",
        "print(arr_max([1]))                # should output 1\n",
        "print(arr_max([]))                 # should output None"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "5\n",
            "5\n",
            "23\n",
            "1\n",
            "1\n",
            "None\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tEO-Ck0jBvLq"
      },
      "source": [
        "## Pytorch practice\n",
        "Pytorch is a GPU-accelerated machine learning framework, which is nicely designed so that very little effort is required to run code on the GPU. \n",
        "\n",
        "In this section we'll practice using Pytorch tensors, which are roughly equivalent to Python lists but with a whole lot of extra capabilities. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_sj3sP1vBvLr",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "86943c35-3904-445b-b453-394fa620ef47"
      },
      "source": [
        "# Import Pytorch and print out its version\n",
        "import torch\n",
        "print(\"Pytorch version:\", torch.__version__)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Pytorch version: 1.8.1+cu101\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7OwDMVpiBvLu"
      },
      "source": [
        "#### Tensor basics"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WGCobGcOBvLv",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "44b3670a-4f88-435c-bda6-83e0d4a532ee"
      },
      "source": [
        "# Tensors can be initialised with Python lists\n",
        "my_list = [1.5, 2.5, 3.5]\n",
        "my_tensor = torch.tensor(my_list)\n",
        "\n",
        "print(my_list, my_tensor)\n",
        "\n",
        "# This is a 1-dimensional tensor as it is just a flat list of values\n",
        "print(len(my_list), len(my_tensor))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.5, 2.5, 3.5] tensor([1.5000, 2.5000, 3.5000])\n",
            "3 3\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XmNcFzQABvLx",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f411c4f7-0099-409a-8a34-6fa1eaa849eb"
      },
      "source": [
        "# Tensors allow for operations to be applied on the whole collection at once\n",
        "print(my_tensor * 2)\n",
        "\n",
        "# What happens if we try the same thing on a python list? Uncomment the\n",
        "# following line and run it to find out\n",
        "# print(my_list / 2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([3., 5., 7.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dzBVFTFDBvL3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a8ca8eb8-7430-4d33-c7b2-72e73409221d"
      },
      "source": [
        "# The data type is inferred when a tensor is initialised. You can access the\n",
        "# data type of a tensor by using `dtype`\n",
        "my_int_tensor = torch.tensor([1, 2, 3])\n",
        "print(my_int_tensor.dtype)\n",
        "\n",
        "# To cast the tensor, use the \"type\" function\n",
        "my_float_tensor = my_int_tensor.type(torch.float)\n",
        "\n",
        "print(my_float_tensor.dtype)\n",
        "print(my_float_tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.int64\n",
            "torch.float32\n",
            "tensor([1., 2., 3.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "eQnEaTnrBvL6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fbba11bf-f141-43b7-f2da-77056fca1a80"
      },
      "source": [
        "# We can specify the dtype when initialising a tensor\n",
        "my_float_tensor = torch.tensor([1, 2, 3], dtype=torch.float)\n",
        "print(my_float_tensor.dtype)\n",
        "\n",
        "# Or we can use float values in our initialisation (by adding a decimal point)\n",
        "my_float_tensor = torch.tensor([1., 2, 3])\n",
        "print(my_float_tensor.dtype)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.float32\n",
            "torch.float32\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zpsskFZ_BvL8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0dc92464-53c4-48af-d45d-91a52eebea4e"
      },
      "source": [
        "# Tensors can be operated on by a scalar\n",
        "my_float_tensor = my_float_tensor * 2.5 + 3\n",
        "\n",
        "# Tensors can operate element-wise on one-another\n",
        "another_tensor = torch.tensor([2, 4, 8])\n",
        "\n",
        "print(my_float_tensor + another_tensor)\n",
        "print(my_float_tensor - another_tensor)\n",
        "print(my_float_tensor * another_tensor)\n",
        "print(my_float_tensor / another_tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 7.5000, 12.0000, 18.5000])\n",
            "tensor([3.5000, 4.0000, 2.5000])\n",
            "tensor([11., 32., 84.])\n",
            "tensor([2.7500, 2.0000, 1.3125])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-h9G6WJ8BvMA"
      },
      "source": [
        "#### Tensor initialisation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bn5Mxeu6BvMB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "440f325b-572e-443f-b9dd-a9ffdefd40e2"
      },
      "source": [
        "# It's common to want a tensor full of zeros or ones.\n",
        "# Pytorch provides helper functions where we simply give our desired size\n",
        "ones_tensor = torch.ones(5)\n",
        "zeros_tensor = torch.zeros(3)\n",
        "print(ones_tensor, zeros_tensor)\n",
        "\n",
        "# We might also like a tensor of increasing numbers\n",
        "range_tensor = torch.arange(5)\n",
        "print(range_tensor)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 1., 1., 1., 1.]) tensor([0., 0., 0.])\n",
            "tensor([0, 1, 2, 3, 4])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GSntTfPVBvMI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bfc2f745-f2bb-47e6-aa4a-a7c2c56b5d15"
      },
      "source": [
        "# Another common tensor is the identity matrix\n",
        "identity_matrix = torch.eye(3)\n",
        "print(identity_matrix)\n",
        "\n",
        "# The identity matrix we created has two dimensions, meaning that it consists of\n",
        "# both rows and columns. The number of rows and columns is called its \"shape\"\n",
        "print(identity_matrix.shape)\n",
        "\n",
        "# We can make our own 2D matrix by manually initialising it with values. This\n",
        "# tensor has two rows and three columns\n",
        "my_matrix = torch.tensor([[0, 1, 2],\n",
        "                          [3, 4, 5]])\n",
        "print(my_matrix.shape) "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 1.]])\n",
            "torch.Size([3, 3])\n",
            "torch.Size([2, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Jm-2rGHaBvMM",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e29c7f5d-d6a2-4861-f0c4-c309bb30945f"
      },
      "source": [
        "# Tensors are stored in row-major form, which means the first dimension represents\n",
        "# the rows in a tensor. Thus, indexing into the first dimension of the tensor will\n",
        "# give us back an entire row\n",
        "print(identity_matrix[0])\n",
        "\n",
        "# We can further index into this row to extract a specific value\n",
        "print(identity_matrix[0][0])\n",
        "\n",
        "# Torch provides a way to index into multiple dimensions at once\n",
        "print(identity_matrix[0, 0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1., 0., 0.])\n",
            "tensor(1.)\n",
            "tensor(1.)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "imNn-iFOBvMP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "49637d65-6a45-462b-8668-de65966db16f"
      },
      "source": [
        "# Let's create a three-dimensional tensor full of zeros\n",
        "zeros_3d = torch.zeros((2, 3, 3))\n",
        "print(zeros_3d.shape)\n",
        "\n",
        "# This tensor has a shape of (2, 3, 3) for a total of 18 values.\n",
        "# We can imagine this as a list of two 3x3 matrices\n",
        "print(zeros_3d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 3, 3])\n",
            "tensor([[[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]],\n",
            "\n",
            "        [[0., 0., 0.],\n",
            "         [0., 0., 0.],\n",
            "         [0., 0., 0.]]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ldFqbqv5GB_3"
      },
      "source": [
        "#### Exercise 3\n",
        "<font color='red'>In the next cell, write a function called `almost_eye` that takes a single argument - an integer `N`. Your function will create an identity matrix of size `NxN`, set the bottom-right value of this matrix to the value of `N`, and return it. Hint: consider using negative indexes  </font>\n",
        "\n",
        "_Ensure that you re-run the cell containing your solution any time you make changes._"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kxUhKJJMGCZ4"
      },
      "source": [
        "# TODO: Code your solution here\n",
        "\n",
        "# SOLUTION:\n",
        "def almost_eye(N):\n",
        "    x = torch.eye(N)\n",
        "    x[-1, -1] = N\n",
        "    return x"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CYpc0MuyHxv3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "179648c5-9cb6-47e1-b09e-fd3c14f97da7"
      },
      "source": [
        "# Test your solution here\n",
        "print(almost_eye(1))\n",
        "# should output [[1]]\n",
        "\n",
        "print(almost_eye(2))\n",
        "# should output [[1, 0],\n",
        "#                [0, 2]]\n",
        "\n",
        "print(almost_eye(3))\n",
        "# should output [[1, 0, 0],\n",
        "#                [0, 1, 0],\n",
        "#                [0, 0, 3]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[1.]])\n",
            "tensor([[1., 0.],\n",
            "        [0., 2.]])\n",
            "tensor([[1., 0., 0.],\n",
            "        [0., 1., 0.],\n",
            "        [0., 0., 3.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "W0XNMM88BvMR"
      },
      "source": [
        "#### Tensor reshaping\n",
        "Tensors can have a shape made up of any number of dimensions, and we can reshape the tensors as we please - as long as it's a valid shape.\n",
        "\n",
        "For example, a completed Sudoku board contains 9x9=81 numbers arranged in a 9x9 matrix. However, these values can be arranged in a number of ways:\n",
        "* a 9x9 grid (shape `(9, 9)`)\n",
        "* a flat list of 81 numbers (shape `(81)`)\n",
        "* three rows of 27 numbers (shape `(3, 27)`)\n",
        "* 27 rows of three columns (shape `(27, 3`)\n",
        "\n",
        "All of these representations are valid, and still represent the same data. Torch allows for us to perform this sort of reshaping with a function called - you guessed it - `reshape`.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dQw-1Madp7ds",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b7abcacd-9f18-4740-8970-7749634f1245"
      },
      "source": [
        "# Let's initialise a 1D tensor with some values\n",
        "range_tensor = torch.tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
        "print(range_tensor)\n",
        "print(range_tensor.shape)\n",
        "\n",
        "# Another valid representation of this data is as a 3x3 matrix\n",
        "range_mat = torch.tensor([[0, 1, 2],\n",
        "                          [3, 4, 5],\n",
        "                          [6, 7, 8]])\n",
        "print(range_mat)\n",
        "print(range_mat.shape)\n",
        "\n",
        "# Both of the above tensors have the same number of elements, which we can see\n",
        "# by calling the \"numel\" function\n",
        "print(range_tensor.numel(), range_mat.numel())"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8])\n",
            "torch.Size([9])\n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n",
            "torch.Size([3, 3])\n",
            "9 9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dkw6N58RBvMS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4ce825ac-89a0-4426-b88f-e14f1a0c1e00"
      },
      "source": [
        "# First, let's create a tensor of numbers 0-9 and observe its shape\n",
        "range_tensor = torch.arange(9, dtype=torch.float)\n",
        "print(range_tensor, range_tensor.shape)\n",
        "\n",
        "# Let's convert this into a 3x3 matrix\n",
        "range_mat = range_tensor.reshape(3, 3)\n",
        "print(range_mat)\n",
        "print(range_mat.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8.]) torch.Size([9])\n",
            "tensor([[0., 1., 2.],\n",
            "        [3., 4., 5.],\n",
            "        [6., 7., 8.]])\n",
            "torch.Size([3, 3])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pciA1SMQBvMV",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e54b3736-f8a6-4383-ad4f-b9cd5d2ea783"
      },
      "source": [
        "# We can reshape tensors without specifying one dimension (indicated by -1), and\n",
        "# Torch is able to infer the missing dimension size\n",
        "range_mat = range_tensor.reshape(-1, 3)\n",
        "print(range_mat.shape)\n",
        "\n",
        "# We can also flatten the tensor to a single dimension using the same trick.\n",
        "# It turns out flattening tensors is really useful for deep learning!\n",
        "# Since fully connected layers only take 1D tensors.\n",
        "# This will produce a 1D tensor of length 9\n",
        "range_tensor = range_mat.reshape(-1)\n",
        "print(range_tensor, range_tensor.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 3])\n",
            "tensor([0., 1., 2., 3., 4., 5., 6., 7., 8.]) torch.Size([9])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9h004T5zBvMY"
      },
      "source": [
        "# Our reshaping has worked so far because we had the right number of elements.\n",
        "# What happens if we try a shape that our data doesn't match? Uncomment each of\n",
        "# the below lines and find out\n",
        "# reshaped_tensor = range_tensor.reshape((3, 4))\n",
        "# reshaped_tensor = range_tensor.reshape((-1, 4))\n",
        "\n",
        "# The two above reshape requests failed as 4 is not a factor of 9. I.e. 9/4\n",
        "# doesn't give a whole number"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Pn_-Ft62BvMb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "662d765d-c47a-4da4-dcb3-fee188eb23e3"
      },
      "source": [
        "# Let's modify a value in our original tensor\n",
        "range_tensor[0] = -1\n",
        "print(range_tensor)\n",
        "print(range_mat)\n",
        "\n",
        "# We modified the original tensor, but values in the reshaped version were changed too!\n",
        "# This is because when possible, reshape just creates a different \"view\" into the\n",
        "# original tensor, so the tensors still share memory."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-1.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.])\n",
            "tensor([[-1.,  1.,  2.],\n",
            "        [ 3.,  4.,  5.],\n",
            "        [ 6.,  7.,  8.]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o7v-QDbBBvMd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c67d3da7-e1d5-48c6-9e64-371ebee19943"
      },
      "source": [
        "# If we don't want them to share memory, we need to explicitly ask for it to be cloned\n",
        "range_tensor_2 = range_tensor.clone()\n",
        "range_tensor_2[0] = 99\n",
        "print(range_tensor)\n",
        "print(range_tensor_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([-1.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.])\n",
            "tensor([99.,  1.,  2.,  3.,  4.,  5.,  6.,  7.,  8.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dz-5ICyxIn79"
      },
      "source": [
        "#### Exercise 4\n",
        "<font color='red'>In the next cell, write a function called `TwoDNumbers` that takes a single argument - an integer `N`. Your function will create an `NxN` matrix containing the values in the range of `[0, N*N)`. Hint: the arange and reshape functions will be useful for this question. </font> \\\n",
        "\n",
        "_Ensure that you re-run the cell containing your solution any time you make changes._"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vdPuh--uI0zo"
      },
      "source": [
        "# TODO: Code your solution here\n",
        "\n",
        "# SOLUTION:\n",
        "def TwoDNumbers(N):\n",
        "    x = torch.arange(N * N)\n",
        "    return x.reshape((N, N))\n",
        "    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0dUAxnvvJBmO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2e9f9107-09e8-4ac0-dc45-4b64e0e78197"
      },
      "source": [
        "# Test your solution here\n",
        "print(TwoDNumbers(1))  # should output [[0]]\n",
        "print(TwoDNumbers(2))  # should output [[0, 1],\n",
        "                       #                [2, 3]]\n",
        "print(TwoDNumbers(3))  # should output [[0, 1, 2],\n",
        "                       #                [3, 4, 5],\n",
        "                       #                [6, 7, 8]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0]])\n",
            "tensor([[0, 1],\n",
            "        [2, 3]])\n",
            "tensor([[0, 1, 2],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDZNf4wJMYia",
        "outputId": "dc3fe42f-fdad-4373-d04e-6a07f84d0b92"
      },
      "source": [
        "# Lets take the output from the TwoDNumbers function and \n",
        "# just set the whole first row into zeros. You can do that as follows:\n",
        "outputMatrix = TwoDNumbers(3)\n",
        "outputMatrix[0] = 0\n",
        "print(outputMatrix)  # should output [[0, 0, 0],\n",
        "                     #                [3, 4, 5],\n",
        "                     #                [6, 7, 8]]\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0, 0, 0],\n",
            "        [3, 4, 5],\n",
            "        [6, 7, 8]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ipZU_FMUL91Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52d68abc-b519-49de-daea-f39a8a46917f"
      },
      "source": [
        "# Python provides a way for us to take a slice from a\n",
        "# list or tensor - instead of providing a single number as an index, we use two\n",
        "# numbers separated by the colon : symbol\n",
        "\n",
        "# Let's create another range tensor to start with\n",
        "range_tensor = torch.arange(10)\n",
        "print(range_tensor)\n",
        "\n",
        "# Get the elements from index 3 to index 5 (not including index 5)\n",
        "print(range_tensor[3:5])\n",
        "\n",
        "# Get the elements from index 0 to index 4 (not including index 4)\n",
        "print(range_tensor[0:4])\n",
        "\n",
        "# If we don't wish to specify an end-point, we don't need to provide a value.\n",
        "# Get all elements until index 4 (not including index 4)\n",
        "print(range_tensor[:4])\n",
        "\n",
        "# Get all elements from index 4 (including index 4)\n",
        "print(range_tensor[4:])\n",
        "\n",
        "# Using negative indexing, get the last 3 elements\n",
        "print(range_tensor[-3:])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([0, 1, 2, 3, 4, 5, 6, 7, 8, 9])\n",
            "tensor([3, 4])\n",
            "tensor([0, 1, 2, 3])\n",
            "tensor([0, 1, 2, 3])\n",
            "tensor([4, 5, 6, 7, 8, 9])\n",
            "tensor([7, 8, 9])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZqHln4EDBvMg"
      },
      "source": [
        "#### More tensor operations"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": true,
        "id": "cMT5IuUUBvMg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "881a1924-c5aa-457e-8ed7-36435f1b5447"
      },
      "source": [
        "# Transpose a tensor (switching its rows and columns)\n",
        "print(range_mat)\n",
        "print(range_mat.T)\n",
        "\n",
        "# Create a tensor full of ones or zeros that has the same shape as another\n",
        "ones_mat = torch.ones_like(range_mat)\n",
        "zeros_mat = torch.zeros_like(ones_mat)\n",
        "print(ones_mat)\n",
        "print(zeros_mat)\n",
        "print(range_mat.shape == ones_mat.shape == zeros_mat.shape)\n",
        "\n",
        "# Create a tensor of random values between 0 and 1\n",
        "rand_mat = torch.rand_like(range_mat)\n",
        "print(rand_mat)\n",
        "\n",
        "# Matrix multiplication\n",
        "print(range_mat @ rand_mat)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[-1.,  1.,  2.],\n",
            "        [ 3.,  4.,  5.],\n",
            "        [ 6.,  7.,  8.]])\n",
            "tensor([[-1.,  3.,  6.],\n",
            "        [ 1.,  4.,  7.],\n",
            "        [ 2.,  5.,  8.]])\n",
            "tensor([[1., 1., 1.],\n",
            "        [1., 1., 1.],\n",
            "        [1., 1., 1.]])\n",
            "tensor([[0., 0., 0.],\n",
            "        [0., 0., 0.],\n",
            "        [0., 0., 0.]])\n",
            "True\n",
            "tensor([[0.3914, 0.1261, 0.6122],\n",
            "        [0.6931, 0.5466, 0.0046],\n",
            "        [0.4278, 0.4728, 0.5037]])\n",
            "tensor([[ 1.1573,  1.3660,  0.3997],\n",
            "        [ 6.0856,  4.9286,  4.3731],\n",
            "        [10.6225,  8.3652,  7.7343]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mB-YRrGdBvMi"
      },
      "source": [
        "#### Concatenation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JUra4y_BvMj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0080952f-c6f2-4fa6-d72d-665bfec64fe1"
      },
      "source": [
        "# Python lists allow for concatenation like list1 + list2, but Torch interprets\n",
        "# tensor1 + tensor2 as a summation. So we instead use the function torch.cat\n",
        "tensor_a = torch.tensor([1, 2, 3, 4])\n",
        "tensor_b = torch.tensor([5, 6, 7])\n",
        "tensor_c = torch.cat((tensor_a, tensor_b))\n",
        "print(tensor_c)\n",
        "\n",
        "# We can concatenate any number of tensors at the same time\n",
        "tensor_d = torch.cat((tensor_a, tensor_a, tensor_b))\n",
        "print(tensor_d)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([1, 2, 3, 4, 5, 6, 7])\n",
            "tensor([1, 2, 3, 4, 1, 2, 3, 4, 5, 6, 7])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wMpBfxzBvMl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb4d673b-e2b7-474d-d756-9f1f537818af"
      },
      "source": [
        "# Let's put together some dummy data.\n",
        "# Each tensor will contain the age, height, and weight of a different person\n",
        "alice_data = torch.tensor([36, 159, 68])\n",
        "bob_data = torch.tensor([29, 174, 76])\n",
        "print(alice_data, alice_data.shape)\n",
        "print(bob_data, bob_data.shape)\n",
        "\n",
        "# Now we'll create a 2x3 matrix where each row is a person's data - we have two\n",
        "# options for this.\n",
        "# Option 1:\n",
        "# - Convert each tensor into a 1x3 matrix\n",
        "alice_data_1 = alice_data.reshape((1, -1))\n",
        "bob_data_1 = bob_data.reshape((1, -1))\n",
        "# - Concatenate the tensors along the first dimension\n",
        "data_matrix_1 = torch.cat((alice_data_1, bob_data_1), dim=0)\n",
        "print(data_matrix_1)\n",
        "\n",
        "# Option 2:\n",
        "# - Use the stack function!\n",
        "data_matrix_2 = torch.stack((alice_data, bob_data), dim=0)\n",
        "print(data_matrix_2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 36, 159,  68]) torch.Size([3])\n",
            "tensor([ 29, 174,  76]) torch.Size([3])\n",
            "tensor([[ 36, 159,  68],\n",
            "        [ 29, 174,  76]])\n",
            "tensor([[ 36, 159,  68],\n",
            "        [ 29, 174,  76]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "goC2RgqXBvMo",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0b6d0a42-6ec9-40ca-d52a-da5bf6db4568"
      },
      "source": [
        "# torch.stack allows us to stack tensors along an arbitrary dimension, as long\n",
        "# as the shapes are compatible. Thus, we can stack along the second dimension\n",
        "# and produce the transpose of our other matrix!\n",
        "print(torch.stack((alice_data, bob_data), dim=1))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 36,  29],\n",
            "        [159, 174],\n",
            "        [ 68,  76]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3UgacTWyOpnu"
      },
      "source": [
        "#### Exercise 5\n",
        "<font color='red'>In the next cell, write a function called `add_person` that takes a matrix (like `data_matrix_1` in the previous cell), and a tensor `new_person` of a person's age, height and weight. It should concatenate the new person to the end of the given matrix and return it. Hint: you need to  reshape the new_person tensor into a 2D matrix first before you can concatenate it. You can not directly concatenate a 1D tensor onto the end of a 2D tensor.</font>\n",
        "\n",
        "_Ensure that you re-run the cell containing your solution any time you make changes._"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R30uKXeEOqgU"
      },
      "source": [
        "# TODO: Code your solution here\n",
        "\n",
        "# SOLUTION:\n",
        "def add_person(people, new_person):\n",
        "    return torch.cat((people, new_person.reshape((1, -1))), 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GGDTzqFpPLBh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e509e7a2-9363-4c05-aa22-16e758b19b4c"
      },
      "source": [
        "# Test your solution here\n",
        "charlie_data = torch.tensor([39, 166, 74])\n",
        "dennis_data = torch.tensor([41, 183, 87])\n",
        "\n",
        "data_matrix_3 = add_person(data_matrix_1, charlie_data)\n",
        "print(data_matrix_3)\n",
        "# should output [[36, 159, 68],\n",
        "#                [29, 174, 76],\n",
        "#                [39, 166, 74]]\n",
        "\n",
        "data_matrix_3 = add_person(data_matrix_3, dennis_data)\n",
        "print(data_matrix_3)\n",
        "# should output [[36, 159, 68],\n",
        "#                [29, 174, 76],\n",
        "#                [39, 166, 74]\n",
        "#                [41, 183, 87]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[ 36, 159,  68],\n",
            "        [ 29, 174,  76],\n",
            "        [ 39, 166,  74]])\n",
            "tensor([[ 36, 159,  68],\n",
            "        [ 29, 174,  76],\n",
            "        [ 39, 166,  74],\n",
            "        [ 41, 183,  87]])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "34s9iu_BBvMs"
      },
      "source": [
        "#### Advanced indexing\n",
        "To practice indexing into different dimensions of a tensor, let's make some dummy image data consisting of red, green and blue values. In Pytorch, this is represented as a 3-dimensional tensor, where the shape is `(3, height, width)`, where the 3 is for the colour channels R, G, and B."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TDKPQphhBvMu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ea6fabc4-0e17-4b66-ad52-f5ef465363f4"
      },
      "source": [
        "# So, let's create some random image-data!\n",
        "num_channels = 3  # the colour channels R, G, B\n",
        "height = 15\n",
        "width = 30\n",
        "\n",
        "img = torch.rand(num_channels, height, width)\n",
        "print(img.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 15, 30])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "i1GXz3lSSXj6"
      },
      "source": [
        "# Before continuing, run this cell to import a library and set up a helper\n",
        "# function to display images\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plt_img_tensor(tensor):\n",
        "    \"\"\"Plot an image tensor using pyplot\"\"\"\n",
        "    if tensor.ndim == 3:\n",
        "        tensor = tensor.permute(1, 2, 0)\n",
        "    plt.imshow(tensor.detach().cpu().numpy(), cmap='Greys_r')\n",
        "    plt.clim(0, 1)\n",
        "    plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "BUWkDh9TBvMx",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "bb398e1f-aa1a-4984-fe48-01496d0763e9"
      },
      "source": [
        "# Let's have a look at the beautiful image we created\n",
        "plt_img_tensor(img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YapepBmoTSky",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "d9239826-c30f-410e-bf21-4526bb890f01"
      },
      "source": [
        "# As the first dimension is the colour channels, we can view just the green channel\n",
        "# by indexing into the first dimension\n",
        "green_channel = img[1]\n",
        "plt_img_tensor(green_channel)\n",
        "print(green_channel.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        },
        {
          "output_type": "stream",
          "text": [
            "torch.Size([15, 30])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESzhmVqIBvM0"
      },
      "source": [
        "#### Exercise 6\n",
        "<font color='red'>In the next cell, store the blue channel of the image in a tensor called `blue_channel`.</font>\n",
        "\n",
        "_Ensure that you re-run the cell containing your solution any time you make changes._"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nCjreXh2BvM0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 232
        },
        "outputId": "a7d79919-2cbb-48fc-d162-7c7a1b48207d"
      },
      "source": [
        "# TODO: Code your solution here\n",
        "\n",
        "# SOLUTION:\n",
        "blue_channel = img[2]\n",
        "print(blue_channel.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([15, 30])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsW_8KU_BvM5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d42685b8-a4f8-4474-89c9-41c5d5c562b9"
      },
      "source": [
        "# Test your solution here\n",
        "print(blue_channel.shape == (height, width))  # Should output True\n",
        "\n",
        "# Note that the above test doesn't confirm that you have the right colour channel,\n",
        "# only that you have *a* colour channel."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "scrolled": false,
        "id": "F88LCtmYBvM8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3f9b00f3-ad27-4db5-cafe-1cee929b0370"
      },
      "source": [
        "# Let's try accessing values of specific pixels\n",
        "# First, we'll access the green value of the top-left pixel (second colour-channel, first row, first column)\n",
        "green_first_row = green_channel[0]\n",
        "green_first_pixel = green_first_row[0]\n",
        "print(green_first_pixel)\n",
        "\n",
        "# We can access the same information using a single line\n",
        "print(img[1, 0, 0])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.9503)\n",
            "tensor(0.9503)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pxUM_YKdBvNA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e2e7a6c4-f142-492c-906f-725163088712"
      },
      "source": [
        "# We've now seen how to access a row of green values, but how would we get all\n",
        "# RGB values for an entire row? Torch allows us to skip indexing on a dimension,\n",
        "# effectively saying \"give me everything in this dimension\".\n",
        "\n",
        "# Let's start with a simpler example before we return to the image.\n",
        "# We'll begin with a 3x3 matrix\n",
        "square_mat = torch.rand(3, 3)\n",
        "print(square_mat)\n",
        "\n",
        "# We can easily take the first row\n",
        "print(square_mat[0])\n",
        "\n",
        "# How do we take the first column? \n",
        "# Remember how we saw the ':' symbol to take a slice? If we don't provide a start\n",
        "# or end index, we actually ask for *all* of the values in that dimension!\n",
        "\n",
        "# So here we use the symbol to take everything in the first dimension, then\n",
        "# choose an index in the second (column) dimension. This gives us a column\n",
        "print(square_mat[:, 0])\n",
        "\n",
        "# Note that it will appear as a row when printed to the screen, but the\n",
        "# important thing is that we have the values of the column we wanted."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([[0.8483, 0.3618, 0.5887],\n",
            "        [0.9066, 0.3573, 0.3920],\n",
            "        [0.4713, 0.3451, 0.4211]])\n",
            "tensor([0.8483, 0.3618, 0.5887])\n",
            "tensor([0.8483, 0.9066, 0.4713])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TODORYImBvNE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7c928330-4c53-468a-94f6-af816b2a1300"
      },
      "source": [
        "# Back to the image example, how would we extract the first row of RGB values?\n",
        "# Think about it in terms of what each dimension represents\n",
        "# The first dimension is the colour channels - we want all of them (:)\n",
        "# The second dimension is the rows - we want the first row (0)\n",
        "# The third dimension is the columns - we want all of them (:)\n",
        "rgb_row = img[:, 0, :]\n",
        "print(rgb_row.shape)\n",
        "\n",
        "# Great! We have a 3x30 matrix, which is num_channels x width.\n",
        "# However, we can write it in a slightly simpler way - we don't need to specify that we want everything\n",
        "# in the last dimension, as this is the default behaviour.\n",
        "rgb_row = img[:, 0]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([3, 30])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cH70lC3RBvNJ"
      },
      "source": [
        "<font color='red'>The next cell, extracts the RGB values of the first column of the image and stores it in a variable called `rgb_col`.</font> \\\n",
        "\n",
        "_Ensure that you re-run the cell containing your solution any time you make changes._"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EicS3TJJBvNJ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9656aa8e-9a49-42b4-8ebc-bf92cc36d2ec"
      },
      "source": [
        "\n",
        "rgb_col = img[:, :, 0]\n",
        "print(rgb_col.shape == (num_channels, height))  "
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cXHVE54pBvNQ"
      },
      "source": [
        "#### Exercise 7\n",
        "<font color='red'>In the next cell, extract the RGB values of the *last* column of the image and store it in a variable called `rgb_col`. Hint the solution is really similar to the previous cell.</font> \\\n",
        "Remember _negative_ indexing?\n",
        "\n",
        "_Ensure that you re-run the cell containing your solution any time you make changes._"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "L0sxb49oBvNQ"
      },
      "source": [
        "# TODO: Code your solution here\n",
        "\n",
        "# SOLUTION\n",
        "rgb_col = img[:, :, -1]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lCp8NtxGBvNU",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcec2f5f-531c-4986-b438-24de7b4552e3"
      },
      "source": [
        "# Test your solution here\n",
        "print(rgb_col.shape == (num_channels, height))  # Should output True\n",
        "\n",
        "# Note that the above test doesn't confirm that you have the right column, only that you have *a* column."
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EXwm_A1-BvNY"
      },
      "source": [
        "#### Exercise 8 (Challenge)\n",
        "<font color='red'>In the next cell, add another row of random RGB data to the image, and store the new image in a variable called `new_img`.</font> \\\n",
        "You'll need to:\n",
        "- Figure out the required shape of the new row\n",
        "- Create random values of that shape\n",
        "- Concatenate the new values to the image\n",
        "\n",
        "_Ensure that you re-run the cell containing your solution any time you make changes._"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AQB5jJITBvNY"
      },
      "source": [
        "# TODO: Code your solution here\n",
        "\n",
        "# SOLUTION\n",
        "new_row = torch.rand(num_channels, 1, width)\n",
        "new_img = torch.cat((img, new_row), 1)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8AJW2PhBvNf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 243
        },
        "outputId": "28866483-2198-4244-9a1b-e0d79f20979a"
      },
      "source": [
        "# Test your solution here\n",
        "print(new_img.shape == (num_channels, height + 1, width))  # Should output True\n",
        "\n",
        "# View the new image\n",
        "plt_img_tensor(new_img)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXAAAADRCAYAAADVLunAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAXS0lEQVR4nO3de5jOdf7H8de7kYxxppxGyFo5ZIV00CY5JIq1SyWbxKaDZCur0kHpsDWVX+yvtIq0JVGIlhyStpPakBwTSTkM4/BzTMbh/ftj7vaapjm85r5vM/u5r9fjuvYy7nnuPZ97bt7uvnN/vx9zd4iISHhOKu4FiIhIdDTARUQCpQEuIhIoDXARkUBpgIuIBKpEUX6xMsmlvXLZClSbfLw6fb9Hd/HvpDlU/hu6BYA9e41uf0wtR7e+vzzd1qucSbffHdxIt5XKVqJbAMhIr0G31Wofodvye0vS7Xe7jtFtldr865OtJQ7TLQDUOXkd3W77vhrd1q+0j25XbT2Vbk9NolMcMf7PGwCklttBt8v2VqTbWr6Fbvcc4kfZD+VS6LbB3lp0CwCHkr+j2+TD/N+nVUfX7nT3XzzhRTrAK5etgHuv6k+1TfbfT9/vtlf5v3yrL7qSbgFgxix+uHw9+BK6zfyoK90+0/tbur3xU+77CwC92vemWwAY9fAD/Dqez6Dby2bxf5D/9Mpeur3h72Xodvip6+kWAJ6sfhndpg0aSrdzr5pPtw0fvIlub6nAT/CtJ22iWwB4qtNzdFtp1h/odtjhYXQ7Y0UVul3SoQXdTpn9N7oFgDVn/Yluz9owgm4bbL8w138ZdAhFRCRQMQ1wM+tkZmvNbL2Z3R2vRYmISMGiHuBmlgTgWQCXAWgEoJeZNYrXwkREJH+xvAJvBWC9u29w90wArwPoFp9liYhIQWIZ4DUBZP9px+bIbT9jZgPMbLGZLT5w6GAMX05ERLI74T/EdPex7t7S3VuWSebfviMiIvmLZYBvAZD9TZKpkdtERKQIxDLAPwdQ38zqmllJAFcDmBmfZYmISEGiPpHH3Y+a2a0A5gJIAjDe3VfFbWUiIpKvmM7EdPfZAGaz/ffHj2Lgvt1Uu2tmG3od37b6iG7PrrKfbgEgJf0uuq3edwLdThy2nW5/P/IDun2kOf+9GFaucG8aOrqPP/W+USn+DLaZR/hLENy7lk6x4q9v022DTP4MTwBokjSYbjv0GE+3aev5Mybvm/8D3S7YxP85bj2Ev1wBADTd04Ruq53Dn33o/EnFePzauXS7dsYndNvvdP4yCAAwavpUur2r21n8HecxLnQmpohIoDTARUQCpQEuIhIoDXARkUBpgIuIBEoDXEQkUBrgIiKB0gAXEQmUBriISKA0wEVEAlWkmxqnHtmH23e8S7UVvhxC3+++ddfRbbmLVtItANz728p0u+nCOXS7rwl/v6+9sY1uR605SrfbW11NtwDw4blOtw9M7kG3GS020+37f3uWble+W5ZuG68fSLcAUKEE/717oldbum135nt0e3w1v2P6gQPv0O0XN/K7zAPA8lnn0O1Hz6+g2/7L76PbU1t1ptu28/hNtN/p+jHdAsAzYx6j26mlbqPbJOS+MbZegYuIBEoDXEQkULFsalzLzBaa2WozW2Vm/OXZREQkZrEcAz8K4E53X2pmZQEsMbP57r46TmsTEZF8RP0K3N3T3X1p5OP9ANYgl02NRUTkxIjLMXAzqwPgbACf5fK5/+xKfzCzcBeKFxGRvMU8wM2sDICpAP7s7vtyfj77rvQpJfndRkREJH8xDXAzOxlZw3uiu0+Lz5JERIQRy7tQDMA4AGvcfWT8liQiIoxYXoG3BnAtgEvMbFnkf/zpUCIiEpOo30bo7h8BsDiuRURECsHc+etbxOr0Zqf40HnVqPbMkw7S9/va+Ey6rfTsa3QLAB/PeopuX+i1lG5rpLWg29+mPEy39iB/fYzSM5vSLQA83+5Vut25ib8WSo0799Bt+hH+Pxq7fdifbuveMZduAWDy0fp0u/+tH+l26Qi+vaPapXRb4qWGdNt4GH9tEwA4fBV/DaAUn023aQPr0u1d6RfT7bhM/ho5d6bcTLcAcM3pY+k244F/0e0dL45e4u4tc96uU+lFRAKlAS4iEigNcBGRQGmAi4gESgNcRCRQGuAiIoHSABcRCZQGuIhIoDTARUQCpQEuIhKoWLZUK7QD6xvgX924U2mvfbMMfb+PdC9JtyO8Ad0CwNuz+FOQK/apTrdd27xEt+cfa0e3zyW3p9vqB7jLGvwko/pQuu09hj/9f393/rlunrGXbndN20W33a/YRrcAUL1JabrdNIk/1fyUJt/T7ajnl9Ft+/fOpNuKl/GngwPA6Ler0O3wt3fQ7eDGpei2X78/0u2C9fx6S6am0S0APNT2Abr988I+hbrv3OgVuIhIoOKxI0+SmX1hZv+Mx4JERIQTj1fgg5G1obGIiBShWLdUSwXQBcCL8VmOiIiwYn0F/gyAoQCO5xVk35X+8JHdMX45ERH5SSx7Yl4OIMPdl+TXZd+V/pSTK0X75UREJIdY98TsamYbAbyOrL0x+S1bREQkJlEPcHe/x91T3b0OgKsBvOfu/JsxRUQkJnofuIhIoOJyJqa7vw/g/Xjcl4iIcIp0V/pap5f12//C7ca+d+5o+n7f+I3R7Z8OjaJbAPii2QS6PVr7EbpdNG0q3Zart4hujzl/WYGD/MbxAIBvvuXfLfpR8610W2Iff7+Z9SvQ7cfnPUG3vWYX7jy0WWOupds2k8+j20+u6023O3teQrc9V99Pt83HdaZbAOhwcAbdbq/CP3/ll55Ct01LPUi3rzetTLffdu1CtwAwrsdRun1gOj8DMtperl3pRUQSiQa4iEigNMBFRAKlAS4iEigNcBGRQGmAi4gESgNcRCRQGuAiIoHSABcRCZQGuIhIoIp0V/qKySno0egcrn30a/p+n+rRgW63H+Z3bQeAOXMvo1v/9nG6TZv+Cd1mbD2Dbnd34b9vu3cV7jIK1/fkd2I/49jFdDvow3/QbXoH/hILrWcsoNtx8/bRLQB8mnoN3fab9Bbdvr/3MN1ecNJZdLsd++k246Mr6BYADl49km63Jc2m29QXN/L3m/YQ3bbtkEy3yx8dTrdZLqXLz9vy66idx+16BS4iEigNcBGRQMW6qXEFM3vTzL4yszVmdn68FiYiIvmL9Rj4KABz3L2HmZUEwB8kFRGRmEQ9wM2sPICLAPQFAHfPBJAZn2WJiEhBYjmEUhfADgAvmdkXZvaimaXkjMxsgJktNrPFu/f8EMOXExGR7GIZ4CUANAcwxt3PBnAQwN05I3cf6+4t3b1lpQo6wiIiEi+xDPDNADa7+2eR37+JrIEuIiJFIOoB7u7bAGwyswaRm9oBWB2XVYmISIFifRfKIAATI+9A2QDg+tiXJCIijJgGuLsvA/CLnZLzklHaMbolt2vzwpr96HX0mrmMbiuuyuuk1Nw9/NgLdDtw0MN0++O4JnT7Xup3dNv/DP609J71xtMtAHSb8zndpqTdSLf3PVGdbg/d8iPdNn6IP8X7wGT+MggAMH9fN7rt6RPo9tixdnR744Vb6XZoSlO67V32Fz/KytfdE+fRbakJT9DtmisX0W3ZsVPottY9m+n2tDsLd7mJTm3fptsz7/mUv+Pncr9ZZ2KKiARKA1xEJFAa4CIigdIAFxEJlAa4iEigNMBFRAKlAS4iEigNcBGRQGmAi4gESgNcRCRQRbor/Y7dOzF2Inf6dr+Z/KnNycca0e3wNRfTLQAcqZNOt11fHki3zZryp9FuTp9Et2ff0pBut71TuMsKfF//E7qd+8KbdNv+jUvodsE/V9Jt1dZb6Pb9X/WlWwA4VrE73W5L5S9v0L9jTbrtuoD/8zZn8h/pts2sZ+gWADbO50+P/6z6O3Q7fSF/Kv2dffhT3u/DDXTb6NFn6RYAfAh/OY3a6/nn7ytUzPV2vQIXEQmUBriISKBi3ZX+djNbZWYrzWySmZWK18JERCR/UQ9wM6sJ4DYALd29CYAkAFfHa2EiIpK/WA+hlACQbGYlAJQGwF+gWEREYhLLlmpbADwF4HsA6QD2uvsvruyefVd6P1C4i6OLiEjeYjmEUhFANwB1AdQAkGJmv3ivUvZd6a2MRb9SERH5mVgOobQH8K2773D3IwCmAbggPssSEZGCxDLAvwdwnpmVNjND1q70a+KzLBERKUgsx8A/A/AmgKUAVkTua2yc1iUiIgWIdVf64QCGx2ktIiJSCEV6LZQzMk/HqE3cvK95Q1v6fme34q/pcVNyMt0CwA0919HtA22voNvhB26i23PvoVNMacg/pXMeLc3fMYDJI/jrQiSld6XbbuNX0e03Zy2n25GD+OuxnPWbS+kWADKH8N+7fzbbQ7eTW35Et6P3jqbb8y6YQ7eNG6bQLQAs792Kbjsf+IxuX2hxLt02e3cA3XafzH8vbh2zlm4B4PUR2+n20vOf5u+4Qu4361R6EZFAaYCLiARKA1xEJFAa4CIigdIAFxEJlAa4iEigNMBFRAKlAS4iEigNcBGRQGmAi4gEytyLbpOFUlXLe51ruCvOTk3mT6Otf9VUup1e5dd0CwDrz95Mtz8cX0S3r5T6hm6rlLmFbhd17Ei3l+8bTLcA8Hnmk3R7/Ttt6DZ1Ln+d+A+rvUe3rc7eQbeN982gWwDo/Nw1dPvs4VPp9uMrxtDtDT360e3LO/vQbfKKCXQLALdPuYxuG6XxlyxIazaebte2+cVeMnnyszbR7fU1NtAtADyztCzdHn71ObqdPaPZEndvmfN2vQIXEQlUgQPczMabWYaZrcx2WyUzm29m6yK/VjyxyxQRkZyYV+ATAHTKcdvdABa4e30ACyK/FxGRIlTgAHf3DwDsznFzNwAvRz5+GcDv4rwuEREpQLTXA6/q7umRj7cBqJpXaGYDAAwAgBJlS0X55UREJKeYf4jpWW9jyfOtLNl3pU9KLhnrlxMRkYhoB/h2M6sOAJFfM+K3JBERYUQ7wGcCuC7y8XUACvcmWhERiRnzNsJJABYBaGBmm82sP4DHAXQws3UA2kd+LyIiRajAH2K6e688PtUuzmsREZFCKNJT6Vs0auyLXnmNasfMr0bf7+y2D9HtHR0vpFsAqPbuYbqtOrsS3f4j7QjdTuS/FahZdSnd3tf8fP6OAaQntafbER9PptvrOw+h26cn96fban9/g247lR9ItwBw+/EWdDv/3wvptsEHZej20h6/p9t5c5bQbZe36RQAcGzKCrp9Dx/Qba9Dzel2aGP+VJTfNFhZcBRR8ss0ugWAEltfpNuVf72HbrvOmahT6UVEEokGuIhIoDTARUQCpQEuIhIoDXARkUBpgIuIBEoDXEQkUBrgIiKB0gAXEQmUBriISKCi3dAhKkfXnITd55aj2q8mVaDvd85Afgf021L406sBYP7ox+h2eOmddLv+mUF0u27WJ3R7Q8av6fa+6bvoFgDaTeV3ea/01DS67bP4Vrpdem0q3Y4bXo9ua1zchW4BYOWtren2xaX8lrHlHryJbqd2nEm3fVdup9uv686mWwDo3ncC3U5szZ8+/sgxvp2+8By6fWjvKXR70eFFdAsAn/e9jW7bty/EVsJzcr9Zr8BFRAKlAS4iEijmeuDjzSzDzFZmu+1JM/vKzJab2XQz4493iIhIXDCvwCcA6JTjtvkAmrh7UwBfA+APVomISFwUOMDd/QMAu3PcNs/dj0Z++ykA/idLIiISF/E4Bt4PwDt5fdLMBpjZYjNbvOvn/w6IiEgMYhrgZnYvgKMAJubVuPtYd2/p7i0rg9+xRkRE8hf1+8DNrC+AywG086Lcl01ERABEOcDNrBOAoQDauPsP8V2SiIgwmLcRTgKwCEADM9tsZv0B/C+AsgDmm9kyM3v+BK9TRERyKNJd6Usk1fYypYdR7baBV9L3+2ZTftv2Jw/xO9gDwKDNyXQ7ee0NdPvYzY3pdlr7HnT768kj6Xbpl/yp5gDQ6YrNdNv73NJ0e+OmBnTbuc1LdNtz4B/otnnNwr2R6oo2B+i21ePc5SMAYPDqhnTbbu/ldHtr93F023Nd4d5sUG9aE7pN28U/vpTXLqLbubvvp9uq3b6m24XXfkG3ANDvEf7vX8N3+9Dt3uEVtSu9iEgi0QAXEQmUBriISKA0wEVEAqUBLiISKA1wEZFAaYCLiARKA1xEJFAa4CIigdIAFxEJlAa4iEigor6cbDRKowxa2HlUO6LpFvp+Txvwb7o98LtP6RYAUm7uRbdjNvDXFrnu5ky6TRv/ON02qTmIbgef3IVuAeCkus3o9v7B6+j2pSufpdtdNYbQbeX7W9PtHZ030i0ATLlgLt02WP5bun2jxAa6vfg0/nosTb/7C91OLVO4C4w2bcH/uWi2tRXddjxckm77WxrdNrlpD912Gb6DbgHg+sn8ngdTxnDXhQKAS/O4Xa/ARUQCFdWu9Nk+d6eZuZlVOTHLExGRvES7Kz3MrBaAjgC+j/OaRESEENWu9BH/g6xdebSdmohIMYjqGLiZdQOwxd2/JNr/7Eqf6f8XzZcTEZFcFPpdKGZWGsAwZB0+KZC7jwUwFgDKJTXWq3URkTiJ5hV4PQB1AXxpZhsBpAJYamb8vmYiIhKzQr8Cd/cVAE776feRId7S3XfGcV0iIlKAaHelFxGRYlbgK3B3z/dURHevE7fViIgIrUhPpS/V2HHmzGNU+/6+6vT9jq7+L7rt2Hwj3QJA+bt+pNvH3hhPt7eOeY5uuw/5im7Xlniebu+p+He6BYA7hvCn6bcdeRXdTnuBP5X+7uf4PxdDvQ3d7nzlTLoFgLfHvka383bx7776VR9+De++yl8KYX4D/pIQB7c/xC8CwB0N36HbXaNK0+25i/nvW5ODT9Ptwab30+3Jf21EtwDQ474jdPtW2d78HT86JtebdSq9iEigNMBFRAKlAS4iEigNcBGRQGmAi4gESgNcRCRQGuAiIoHSABcRCZQGuIhIoDTARUQCZe5Fd4luM9sB4LtcPlUFQKJezTCRHxugxxc6Pb4w1Hb3U3PeWKQDPC9mttjdWxb3Ok6ERH5sgB5f6PT4wqZDKCIigdIAFxEJ1H/LAB9b3As4gRL5sQF6fKHT4wvYf8UxcBERKbz/llfgIiJSSBrgIiKBKtYBbmadzGytma03s7uLcy0ngpltNLMVZrbMzBYX93piZWbjzSzDzFZmu62Smc03s3WRXysW5xpjkcfje9DMtkSew2Vm1rk41xgtM6tlZgvNbLWZrTKzwZHbE+L5y+fxJcTzl5diOwZuZkkAvgbQAcBmAJ8D6OXuq4tlQSeAmW0E0NLdE+FEApjZRQAOAPiHuzeJ3JYGYLe7Px75R7iiu99VnOuMVh6P70EAB9z9qeJcW6zMrDqA6u6+1MzKAlgC4HcA+iIBnr98Ht+VSIDnLy/F+Qq8FYD17r7B3TMBvA6gWzGuRwrg7h8A2J3j5m4AXo58/DKy/tIEKY/HlxDcPd3dl0Y+3g9gDYCaSJDnL5/Hl9CKc4DXBLAp2+83I/G+4Q5gnpktMbMBxb2YE6Squ6dHPt4GoGpxLuYEudXMlkcOsQR5iCE7M6sD4GwAnyEBn78cjw9IsOcvO/0Q88S60N2bA7gMwMDIf6InLM86Hpdo70sdA6AegGYA0gE8XbzLiY2ZlQEwFcCf3X1f9s8lwvOXy+NLqOcvp+Ic4FsA1Mr2+9TIbQnD3bdEfs0AMB1Zh40SzfbI8cefjkNmFPN64srdt7v7MXc/DuAFBPwcmtnJyBpuE919WuTmhHn+cnt8ifT85aY4B/jnAOqbWV0zKwngagAzi3E9cWVmKZEfpsDMUgB0BLAy//9XkGYCuC7y8XUAZhTjWuLup+EW0R2BPodmZgDGAVjj7iOzfSohnr+8Hl+iPH95KdYzMSNv6XkGQBKA8e7+aLEtJs7M7AxkveoGgBIAXgv98ZnZJAAXI+sSndsBDAfwFoApAE5H1qWCr3T3IH8QmMfjuxhZ//ntADYCuDHbMeNgmNmFAD4EsALA8cjNw5B1nDj45y+fx9cLCfD85UWn0ouIBEo/xBQRCZQGuIhIoDTARUQCpQEuIhIoDXARkUBpgIuIBEoDXEQkUP8PoapjgbR0z7kAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}